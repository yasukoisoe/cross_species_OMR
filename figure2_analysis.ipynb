{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import os\n",
    "\n",
    "savefolder = \"/Users/your/savefolder\"\n",
    "datafolder = \"/Users/your/datafolder\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed002c",
   "metadata": {},
   "source": [
    "## Figure 2 a-e Analysis of wall effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e46f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure 2 a-e\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import os\n",
    "\n",
    "\n",
    "### stimuli in the whole rig\n",
    "# exp_name = \"zebra_sine\"\n",
    "# color = \"blue\"\n",
    "# data = pd.read_pickle(r\"%s/df_zebrafish_sinegrating.pkl\" % datafolder)\n",
    "\n",
    "exp_name = \"medaka_sine\"\n",
    "color = \"orange\"\n",
    "data = pd.read_pickle(r\"%s/df_Medaka_sinegrating.pkl\" % datafolder)\n",
    "\n",
    "### stimuli in the restricted area\n",
    "exp_name = \"zebra_sine_restrict\"\n",
    "color = \"blue\"\n",
    "data = pd.read_pickle(r\"%s/df_zebrafish_sinegrating_moving_black.pkl\" % datafolder)\n",
    "\n",
    "# exp_name = \"medaka_sine_restrict\"\n",
    "# color = \"orange\"\n",
    "# data = pd.read_pickle(r\"%s/df_Medaka_sinegrating_moving_white.pkl\" % datafolder)\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analyze experimental results in response to leftward and rightward stimuli\n",
    "## Analyze the turn angle depending on the distance to the wall\n",
    "\n",
    "stimulus = 4\n",
    "fish_n = 30\n",
    "\n",
    "## for figure in paper\n",
    "\n",
    "data_frame = []\n",
    "l_stim_data = data.loc[(data['stimulus_index'] == 1)]\n",
    "r_stim_data = data.loc[(data['stimulus_index'] == 3)]\n",
    "df = r_stim_data.copy()\n",
    "df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "    \n",
    "merge_data = [l_stim_data, df]\n",
    "big_data = pd.concat(merge_data)\n",
    "\n",
    "trial_num = 15\n",
    "time_start = 5\n",
    "time_stop = 25\n",
    "start_timing = 0\n",
    "middle_timing = time_start\n",
    "stop_timing = time_stop\n",
    "dt = 1./ 90\n",
    "binning1 = np.arange(start_timing, stop_timing-0.1, 0.05)\n",
    "analysis_bin = np.arange(start_timing, stop_timing-0.1, 0.2)\n",
    "\n",
    "columns = [\"bin_n\", \"density\", \"pattern\", \"tbin\"]\n",
    "data_frame = [] #pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "distance_to_wall = np.arange(0, 70, 10)\n",
    "for d in range(len(distance_to_wall)-1):\n",
    "    selected_data = big_data.loc[(big_data['center_distance']< (60 - distance_to_wall[d])) & (big_data['center_distance'] > (60 - distance_to_wall[d+1]))]\n",
    "    \n",
    "    fig, axs = plt.subplots(5, figsize=(4,9))\n",
    "    \n",
    "    stimuli = []\n",
    "\n",
    "    for t in binning1:\n",
    "        if t < 5:\n",
    "            stimuli.append(0)\n",
    "        else:\n",
    "            stimuli.append(1)\n",
    "    \n",
    "    axs[0].axvline(x=5, color='black', alpha=0.5, linestyle=\"--\")\n",
    "    axs[0].plot(binning1, stimuli, color=\"red\")\n",
    "    axs[0].set_ylim(-1.1, 1.1)\n",
    "    axs[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "    axs[0].set_ylabel(\"stimulus\")\n",
    "    axs[0].set_xlim(3, 15)\n",
    "    \n",
    "    print(len(selected_data[\"start_time_index\"])/5000)\n",
    "    axs[1].axvline(x=5, color='black', alpha=0.5, linestyle=\"--\")\n",
    "    axs[1].scatter(selected_data[\"start_time_index\"], y=selected_data[\"bout_angle\"], color=color, alpha=0.6, marker=\".\", s=0.5/(len(selected_data[\"start_time_index\"])/9000), )\n",
    "    axs[1].set_ylim(-100, 100)\n",
    "    axs[1].set_xlim(3, 15) #rest + pulse)\n",
    "    axs[1].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"%s/fig_%s_distance%s_scatter.png\" % (savefolder, exp_name, d),\n",
    "                        transparent=True)\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(5, figsize=(4,9))\n",
    "    axs[0].axvline(x=5, color='black', alpha=0.5, linestyle=\"--\")\n",
    "    axs[0].plot(binning1, stimuli, color=\"red\")\n",
    "    axs[0].set_ylim(-1.1, 1.1)\n",
    "    axs[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "    axs[0].set_ylabel(\"stimulus\")\n",
    "    axs[0].set_xlim(3, 15)\n",
    "\n",
    "    show_t = []\n",
    "\n",
    "    ave_angles = []\n",
    "    std_angles = []\n",
    "    for t_bin in range(len(analysis_bin)-1):\n",
    "        data_sub = selected_data.loc[(selected_data[\"start_time_index\"] > analysis_bin[t_bin]) & (selected_data[\"start_time_index\"] < analysis_bin[t_bin+1])]\n",
    "        show_t.append((analysis_bin[t_bin+1] + analysis_bin[t_bin])/2)\n",
    "        ave_angles.append(data_sub[\"bout_angle\"].mean())\n",
    "        std_angles.append(data_sub[\"bout_angle\"].std()/np.sqrt(fish_n))\n",
    "\n",
    "    axs[2].axvline(x=5, color='black', alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "    axs[2].fill_between(show_t, np.array(ave_angles) - np.array(std_angles), np.array(ave_angles) + np.array(std_angles), color=color, alpha=0.3)\n",
    "    axs[2].plot(show_t, ave_angles, color=color, alpha=1, )\n",
    "    axs[2].set_ylim(-50, 50)\n",
    "    axs[2].axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "    axs[2].set_xlim(3, 15)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"%s/fig_%s_distance%s_average.svg\" % (savefolder, exp_name, d),\n",
    "                        transparent=True)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_wall = np.arange(0, 70, 10)\n",
    "ave_angles_whole, std_angles_whole = [], []\n",
    "for d in range(len(distance_to_wall)-1):\n",
    "    selected_data = big_data.loc[(big_data['center_distance']< (60 - distance_to_wall[d])) & (big_data['center_distance'] > (60 - distance_to_wall[d+1]))]\n",
    "    data_sub = selected_data.loc[(selected_data[\"start_time_index\"] > 10) & (selected_data[\"start_time_index\"] < 25)]\n",
    "    ave_angles_whole.append(data_sub[\"bout_angle\"].mean())\n",
    "    std_angles_whole.append(data_sub[\"bout_angle\"].std()/np.sqrt(fish_n))                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "showx = distance_to_wall[:-1]\n",
    "plt.plot(showx, ave_angles_whole, color=color, linestyle=\"--\", marker=\"o\")\n",
    "plt.fill_between(showx, np.array(ave_angles_whole) - np.array(std_angles_whole), np.array(ave_angles_whole) + np.array(std_angles_whole), color=color, alpha=0.3)\n",
    "plt.ylim(-15, 45)\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.savefig(\"%s/medaka_whole_res_dis_resrigonly.svg\" % (savefolder))\n",
    "# plt.ylim(0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare how much the turning is suppressed by the wall\n",
    "## \n",
    "showx_zs = [0, 10, 20,30, 40,]\n",
    "showx_ms = [3, 13, 23,33, 43,]\n",
    "fish_number = 31\n",
    "\n",
    "      \n",
    "l_stim_data = data.loc[(data['stimulus_index'] == 1)]\n",
    "r_stim_data = data.loc[(data['stimulus_index'] == 3)]\n",
    "l2_stim_data = data.loc[(data['stimulus_index'] == 5)]\n",
    "r2_stim_data = data.loc[(data['stimulus_index'] == 7)]\n",
    "df = r_stim_data.copy()\n",
    "df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "\n",
    "df2 = r2_stim_data.copy()\n",
    "df2['bout_angle'] = r2_stim_data['bout_angle'] * (-1)\n",
    "    \n",
    "merge_data = [l_stim_data, df, l2_stim_data, df2]\n",
    "big_data = pd.concat(merge_data)\n",
    "        \n",
    "distance_to_wall = np.arange(0, 60, 10)\n",
    "ave_angles_whole, std_angles_whole = [], []\n",
    "deviation_ave, deviation_ste = [], []\n",
    "\n",
    "for d in range(len(distance_to_wall)-1):\n",
    "#     print(d)\n",
    "    deviation_d = []\n",
    "\n",
    "    for fish in range(fish_number):\n",
    "\n",
    "        selected_data = big_data.loc[(big_data['fish_index'] == fish) & (big_data['center_distance']< 10) & (big_data['center_distance'] > 0)]\n",
    "        data_sub = selected_data.loc[(selected_data[\"start_time_index\"] > 10) & (selected_data[\"start_time_index\"] < 25)]\n",
    "        center_ang = data_sub[\"bout_angle\"].mean()\n",
    "        selected_data = big_data.loc[(big_data['fish_index'] == fish) & (big_data['center_distance']< (60 - distance_to_wall[d])) & (big_data['center_distance'] > (60 - distance_to_wall[d+1]))]\n",
    "        data_sub = selected_data.loc[(selected_data[\"start_time_index\"] > 10) & (selected_data[\"start_time_index\"] < 25)]\n",
    "        deviation_d.append(data_sub[\"bout_angle\"].mean() - center_ang)\n",
    "\n",
    "    deviation_ave.append(np.nanmean(deviation_d))\n",
    "    deviation_ste.append(np.nanstd(deviation_d)/np.sqrt(fish_number))\n",
    "\n",
    "print(deviation_ave)\n",
    "print(deviation_ste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5009d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_whole_dev_ave = [-25.33239944217422, -23.852899893084665, -18.040117067402313, -12.867724877950236, -6.297446879758722]\n",
    "z_whole_dev_ste = [2.0248607098462648, 1.7801381344001175, 1.9312973368514312, 1.1191374963583096, 0.6273150125466831]\n",
    "m_whole_dev_ave =[-38.80999483483591, -38.061034562023146, -38.100628927635622, -29.08004669255537, -15.507523462354678]\n",
    "m_whole_dev_ste =[3.426523755644862, 3.241422344951606, 2.6765856375018977, 2.2453299781327374, 1.6046445309778317]\n",
    "z_restr_dev_ave = [0.4853243280364952, 3.7949832522260945, 4.384792205246315, 3.0417940581166545, 3.1998332607502147]\n",
    "z_restr_dev_ste = [2.0494075213534386, 1.9154798966318793, 1.8742180355853217, 2.0401721990719204, 1.9068000252383521]\n",
    "m_restr_dev_ave = [-19.615842214471282, -10.022295163234985937, -3.09431062848186698, -1.9261421037229394, -1.3671018989670916]\n",
    "m_restr_dev_ste = [5.617899014040034, 3.238062957696074, 2.7689549096626127, 2.5354430287452803, 2.383200383871117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "showx_zs = [0, 10, 20,30, 40,]\n",
    "showx_ms = [3, 13, 23,33, 43,]\n",
    "\n",
    "fig, axs = plt.subplots(1, figsize=(2,1))\n",
    "plt.bar(showx_zs, z_whole_dev_ave, color=\"blue\", width=2)\n",
    "plt.errorbar(showx_zs, z_whole_dev_ave, yerr=z_whole_dev_ste, color=\"blue\", fmt=\" \")\n",
    "plt.bar(showx_ms, m_whole_dev_ave, width=2,color=\"orange\")\n",
    "plt.errorbar(showx_ms, m_whole_dev_ave, yerr=m_whole_dev_ste, color=\"orange\", fmt=\" \")\n",
    "plt.ylim(-45, 7)\n",
    "plt.axhline(0, color=\"black\",linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"%s/fig_sine_whole_deviation.svg\" % (savefolder),\n",
    "                        transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## for statistics\n",
    "# Make a DataFrame with columns:\n",
    "# 'fish_id', 'species', 'spatial_bin', 'turning_angle', \"whole_or_not\" (whole is 0, restrict is 1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_stats = pd.DataFrame(columns=['fish_id', 'species', 'spatial_bin', 'turning_angle', \"whole_or_not\"])\n",
    "\n",
    "species = [\"zebrafish\", \"medaka\", \"zebrafish\", \"medaka\"]\n",
    "exp_names = [\"zebra_sine\", \"medaka_sine\", \"zebra_sine_restrict\", \"medaka_sine_restrict\"]\n",
    "data_names = [\"zebrafish_sinegrating\", \"Medaka_sinegrating\",\n",
    "             \"zebrafish_sinegrating_moving_black\", \"Medaka_sinegrating_moving_white\"]\n",
    "whole_or_nots =[0, 0, 1, 1]\n",
    "fish_number_id = 0\n",
    "\n",
    "for exp_name_i, exp_name in enumerate(exp_names):\n",
    "    \n",
    "    data = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, data_names[exp_name_i]))\n",
    "    \n",
    "    data_frame = []\n",
    "    if max(data[\"stimulus_index\"]) > 4:\n",
    "        \n",
    "        l_stim_data = data.loc[(data['stimulus_index'] == 1)]\n",
    "        r_stim_data = data.loc[(data['stimulus_index'] == 3)]\n",
    "        l2_stim_data = data.loc[(data['stimulus_index'] == 5)]\n",
    "        r2_stim_data = data.loc[(data['stimulus_index'] == 7)]\n",
    "        df = r_stim_data.copy()\n",
    "        df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "\n",
    "        df2 = r2_stim_data.copy()\n",
    "        df2['bout_angle'] = r2_stim_data['bout_angle'] * (-1)\n",
    "        merge_data = [l_stim_data, df, l2_stim_data, df2]\n",
    "    else:\n",
    "        data_frame = []\n",
    "        l_stim_data = data.loc[(data['stimulus_index'] == 1)]\n",
    "        r_stim_data = data.loc[(data['stimulus_index'] == 3)]\n",
    "        df = r_stim_data.copy()\n",
    "        df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "\n",
    "        merge_data = [l_stim_data, df]\n",
    "        \n",
    "    big_data = pd.concat(merge_data)\n",
    "\n",
    "    trial_num = 15\n",
    "    time_start = 5\n",
    "    time_stop = 25\n",
    "    start_timing = 0\n",
    "    middle_timing = time_start\n",
    "    stop_timing = time_stop\n",
    "    dt = 1./ 90\n",
    "    binning1 = np.arange(start_timing, stop_timing-0.1, 0.05)\n",
    "    analysis_bin = np.arange(start_timing, stop_timing-0.1, 0.2)\n",
    "\n",
    "    columns = [\"bin_n\", \"density\", \"pattern\", \"tbin\"]\n",
    "    data_frame = [] #pd.DataFrame(columns=columns)\n",
    "\n",
    "    distance_to_wall = np.arange(0, 70, 10)\n",
    "    fish_number = max(big_data[\"fish_index\"])\n",
    "    \n",
    "    for fish in range(fish_number):\n",
    "        fish_number_id = fish_number_id+1\n",
    "        fish_big_data = big_data.loc[(big_data[\"fish_index\"]== fish)]\n",
    "            \n",
    "        for d in range(len(distance_to_wall)-1):\n",
    "            selected_data = fish_big_data.loc[(fish_big_data['center_distance']< (60 - distance_to_wall[d])) & (fish_big_data['center_distance'] > (60 - distance_to_wall[d+1]))]\n",
    "            ave_angle = np.nanmean(selected_data[\"bout_angle\"])\n",
    "            \n",
    "            df2 = pd.DataFrame({\n",
    "            'fish_id': fish_number_id,\n",
    "                    'species': species[exp_name_i],\n",
    "                    'spatial_bin': d,\n",
    "            \"turning_angle\": ave_angle,\n",
    "                \"whole_or_not\": whole_or_nots[exp_name_i]\n",
    "                }, index=[0]) \n",
    "            df_stats = pd.concat([df_stats, pd.DataFrame(df2)], ignore_index=True)\n",
    "            \n",
    "df_stats.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73369211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## want to do the statistics\n",
    "## compare between zebrafish and medaka across each\n",
    "## this is from Claud\n",
    "\n",
    "# !pip install pingouin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import pingouin as pg\n",
    "\n",
    "# Assuming your data is in a DataFrame with columns:\n",
    "# 'fish_id', 'species', 'spatial_bin', 'turning_angle'\n",
    "\n",
    "# Perform two-way mixed ANOVA\n",
    "df = df_stats.loc[df_stats[\"whole_or_not\"]==1]\n",
    "aov = pg.mixed_anova(data=df, dv='turning_angle', \n",
    "                     within='spatial_bin', between='species', \n",
    "                     subject='fish_id')\n",
    "\n",
    "# Print ANOVA results\n",
    "print(aov)\n",
    "\n",
    "# If interaction is significant, perform simple main effects analysis\n",
    "# Simple effect of species at each spatial bin\n",
    "simple_effects = []\n",
    "for bin_n in range(0, 6):\n",
    "\n",
    "    bin_data = df[df['spatial_bin'] == bin_n]\n",
    "    result = pg.ttest(bin_data[bin_data['species'] == 'zebrafish']['turning_angle'],\n",
    "                          bin_data[bin_data['species'] == 'medaka']['turning_angle'],\n",
    "                          paired=False)\n",
    "\n",
    "    result['spatial_bin'] = bin_n\n",
    "    simple_effects.append(result)\n",
    "    \n",
    "simple_effects_df = pd.concat(simple_effects).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Apply correction for multiple comparisons\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "_, simple_effects_df['p_adj'], _, _ = multipletests(\n",
    "        simple_effects_df['p-val'], method='bonferroni')\n",
    "    \n",
    "print(simple_effects_df)\n",
    "\n",
    "\n",
    "# If main effect of spatial bin is significant, perform pairwise comparisons\n",
    "medaka_df = df.loc[df[\"species\"]=='zebrafish']\n",
    "zebrafish_df = df.loc[df[\"species\"]=='medaka']\n",
    "print(\"medaka!\")\n",
    "posthoc_m = pg.pairwise_ttests(data=medaka_df, dv='turning_angle', \n",
    "                                 within='spatial_bin', subject='fish_id',\n",
    "                                 padjust='bonferroni')\n",
    "print(posthoc_m)\n",
    "\n",
    "print(\"zebrafish!\")\n",
    "posthoc_z = pg.pairwise_ttests(data=zebrafish_df, dv='turning_angle', \n",
    "                                 within='spatial_bin', subject='fish_id',\n",
    "                                 padjust='bonferroni')\n",
    "print(posthoc_z)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc88f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare between whole and restricted\n",
    "print(\"compare between whole and restricted\")\n",
    "species_category = [\"medaka\", \"zebrafish\"]\n",
    "\n",
    "for sp_n in species_category:\n",
    "    df2 = df_stats.loc[df_stats[\"species\"]== sp_n]\n",
    "    print(\"result of \", sp_n)\n",
    "    \n",
    "    aov = pg.mixed_anova(data=df2, dv='turning_angle', \n",
    "                     within='spatial_bin', between='whole_or_not', \n",
    "                     subject='fish_id')\n",
    "\n",
    "    # Print ANOVA results\n",
    "    print(aov)\n",
    "    \n",
    "    simple_effects = []\n",
    "    for bin_n in range(0, 6):\n",
    "\n",
    "        bin_data = df2[df2['spatial_bin'] == bin_n]\n",
    "        result = pg.ttest(bin_data[bin_data['whole_or_not'] == 0]['turning_angle'],\n",
    "                              bin_data[bin_data['whole_or_not'] == 1]['turning_angle'],\n",
    "                              paired=False)\n",
    "\n",
    "        result['spatial_bin'] = bin_n\n",
    "        simple_effects.append(result)\n",
    "\n",
    "    simple_effects_df = pd.concat(simple_effects).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # Apply correction for multiple comparisons\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "    _, simple_effects_df['p_adj'], _, _ = multipletests(\n",
    "            simple_effects_df['p-val'], method='bonferroni')\n",
    "\n",
    "    print(simple_effects_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e89038",
   "metadata": {},
   "source": [
    "## Figure 2 f-j Stimuli with different size of motion disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ebbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bring the dataset from the actual turning at the sandblasted rig\n",
    "## for each fish, see the height, amplitude and calculate the saturation point?\n",
    "## for each fish, fit with the curve\n",
    "## measure the threshold size\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "from scipy import interpolate\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import os\n",
    "\n",
    "scales = [0.1, 0.2,0.26,0.33, 0.5, 1]\n",
    "directions = [-90, 90]\n",
    "\n",
    "### dots\n",
    "## datasets are already screened based on the activity of fish.\n",
    "## only the fish who swam close to the center, in response to the open-loop converging stimuli, were screened.\n",
    "exp_name1 = \"diff_dot_disk_size_exp_zebra_sandblast_good_rig_last\" \n",
    "good_fishs1 =[\"2024_11_16_fish106\", \"2024_11_16_fish115\", \"2024_11_16_fish119\", \"2024_11_17_fish122\", \"2024_11_17_fish133\"]\n",
    "\n",
    "exp_name2 = \"diff_dot_disk_size_exp_zebrafish_sandblast_good_rig_last_last\"\n",
    "good_fishs2 = [\"2025_01_21_fish001\", \"2025_01_21_fish003\", \"2025_01_21_fish010\", \"2025_01_21_fish011\", \n",
    "\"2025_01_22_fish021\", ]\n",
    "\n",
    "exp_name3 = \"diff_dot_disk_size_exp_medaka_sandblast_good_rig_last\"\n",
    "good_fishs3 = [\"2024_11_16_fish129\", \"2024_11_17_fish114\", \"2024_11_17_fish116\"]\n",
    "\n",
    "exp_name4 = \"diff_dot_disk_size_exp_medaka_sandblast_good_rig_last_last\"\n",
    "good_fishs4=[\"2025_01_13_fish001\", \"2025_01_13_fish003\", \"2025_01_13_fish007\", \"2025_01_13_fish009\", \"2025_01_13_fish010\", \"2025_01_13_fish011\",\n",
    "            \"2025_01_14_fish016\", \"2025_01_14_fish025\" \n",
    "]\n",
    "\n",
    "color12 = \"blue\"\n",
    "color34 = \"orange\"\n",
    "\n",
    "data1 = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, exp_name1))\n",
    "data2 = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, exp_name2))\n",
    "data3 = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, exp_name3))\n",
    "data4 = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, exp_name4))\n",
    "\n",
    "\n",
    "### make a summary graphs for different size of discs\n",
    "## different size of disk\n",
    "exp_names = [\"diff_dot_disk_size_exp_medaka_sandblast_good_rig_last_2data\", \"diff_dot_disk_size_exp_zebra_sandblast_good_rig_last_2data\",]\n",
    "\n",
    "## different size of disk\n",
    "angless = [19,  36, 50, 65, 80.5,83]\n",
    "scales = [0.1*30, 0.2*30,0.26*30,0.33*30, 0.5*30, 1*30]\n",
    "\n",
    "colors = [ \"orange\" ,\"blue\",]\n",
    "\n",
    "\n",
    "stimulus_pattern = []\n",
    "patterns = [0, 2,4,6,8, 10]\n",
    "\n",
    "trial_num = 20\n",
    "time_start = 5\n",
    "time_stop = 25\n",
    "start_timing = 0\n",
    "middle_timing = time_start\n",
    "stop_timing = time_stop\n",
    "dt = 1./ 90\n",
    "binning1 = np.arange(start_timing, stop_timing-0.1, 0.05)\n",
    "analysis_bin = np.arange(start_timing, stop_timing-0.1, 0.2)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "r = 2  # radius of circular dot (mm)\n",
    "d = 5  # speed of dot movement along x-axis (mm/s)\n",
    "\n",
    "def interpolate_data(time, values, new_time_points, method='linear'):\n",
    "        \n",
    "    # Create interpolation function\n",
    "    f = interpolate.interp1d(time, values, kind=method, bounds_error=False, fill_value=\"extrapolate\")\n",
    "    # Get new values using the interpolation function\n",
    "    new_values = f(new_time_points)\n",
    "    return new_values\n",
    "\n",
    "# Functions for calculating angles and derivatives\n",
    "def calculate_theta(x, y, h):\n",
    "    distance = np.sqrt(x**2 + y**2 + h**2)\n",
    "    theta = np.arccos(h / distance) * 180 / np.pi\n",
    "    return theta\n",
    "\n",
    "def calculate_phi(x, y, h, r):\n",
    "    distance = np.sqrt(x**2 + y**2 + h**2)\n",
    "    phi = np.arcsin(r / distance) * 180 / np.pi\n",
    "    return phi\n",
    "\n",
    "def dtheta_dx(x, y, h):\n",
    "    distance = np.sqrt(x**2 + y**2 + h**2)\n",
    "    \n",
    "    # Use numpy's where to handle array inputs\n",
    "    denominator = distance**2 * np.sqrt(distance**2 - h**2)\n",
    "    # Create a condition mask\n",
    "    mask = (distance**2 <= h**2)\n",
    "    \n",
    "    # Use where to handle the condition\n",
    "    result = np.where(mask, 0, (x * h) / denominator * 180 / np.pi)\n",
    "    return result\n",
    "\n",
    "def dphi_dx(x, y, h, r):\n",
    "    distance = np.sqrt(x**2 + y**2 + h**2)\n",
    "    \n",
    "    # Create a condition mask\n",
    "    mask = (distance <= r)\n",
    "    \n",
    "    # Handle array inputs\n",
    "    denominator = distance**2 * np.sqrt(1 - (r/distance)**2)\n",
    "    result = np.where(mask, 0, -r * x / denominator * 180 / np.pi)\n",
    "    return result\n",
    "\n",
    "def dtheta_dt(x, y, h, speed):\n",
    "    return dtheta_dx(x, y, h) * speed\n",
    "\n",
    "def dphi_dt(x, y, h, r, speed):\n",
    "    return dphi_dx(x, y, h, r) * speed\n",
    "\n",
    "# Motion energy definitions\n",
    "def energy_abs_product(x, y, h, r, speed):\n",
    "    \"\"\"Absolute product of angular rates\"\"\"\n",
    "    dt_dt = dtheta_dt(x, y, h, speed)\n",
    "    dp_dt = dphi_dt(x, y, h, r, speed)\n",
    "    return np.abs(dt_dt * dp_dt)\n",
    "\n",
    "\n",
    "# Function to calculate total energy in a disk\n",
    "def calculate_total_energy(disk_radius, energy_func, h, r, speed, num_samples=500):\n",
    "    \"\"\"\n",
    "    Calculate total energy in a disk by numerical integration.\n",
    "    \"\"\"\n",
    "    # Create a grid of points within the disk\n",
    "    theta = np.linspace(0, 2*np.pi, num_samples)\n",
    "    # Start with a small positive value to avoid the origin\n",
    "    radius = np.linspace(0.5, disk_radius, num_samples//10)  # Start at 0.5 instead of 0\n",
    "    \n",
    "    # Convert to Cartesian coordinates\n",
    "    theta_grid, radius_grid = np.meshgrid(theta, radius)\n",
    "    x_grid = radius_grid * np.cos(theta_grid)\n",
    "    y_grid = radius_grid * np.sin(theta_grid)\n",
    "    \n",
    "    # Calculate energy at each point\n",
    "    energy_values = energy_func(x_grid, y_grid, h, r, speed)\n",
    "    \n",
    "    # Integrate over the disk (using polar coordinates)\n",
    "    # In polar coordinates, dA = r dr dθ\n",
    "    total_energy = 0\n",
    "    for i in range(len(radius)-1):\n",
    "        r_inner = radius[i]\n",
    "        r_outer = radius[i+1]\n",
    "        r_mid = (r_inner + r_outer) / 2\n",
    "        for j in range(len(theta)-1):\n",
    "            theta_span = theta[j+1] - theta[j]\n",
    "            area_element = r_mid * (r_outer - r_inner) * theta_span\n",
    "            total_energy += energy_values[i, j] * area_element\n",
    "            \n",
    "    return total_energy\n",
    "\n",
    "\n",
    "# Calculate total energy for different disk radii\n",
    "\n",
    "def calculate_total_energy_fit(disk_radii, *p):\n",
    "    h, Amp = p\n",
    "    total_energy_abs_product = []\n",
    "        \n",
    "    for disk_radius in disk_radii:\n",
    "        total_energy_abs_product.append(Amp * calculate_total_energy(disk_radius, energy_abs_product, h, r, d))\n",
    "        \n",
    "    return total_energy_abs_product\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(5, 5))\n",
    "\n",
    "threshold_means, threshold_stds, threshold_Data = [], [], []\n",
    "\n",
    "for exp_name_i, exp_name in reversed(list(enumerate(exp_names))):\n",
    "    print(exp_name)\n",
    "    \n",
    "    if exp_name_i == 0:\n",
    "        # medaka\n",
    "        Data1, Data2 = data3, data4\n",
    "        color = color34\n",
    "        good_Fishs1, good_Fishs2 = good_fishs3, good_fishs4\n",
    "        \n",
    "    else:\n",
    "        Data1, Data2 = data1, data2\n",
    "        color = color12\n",
    "        good_Fishs1, good_Fishs2 = good_fishs1, good_fishs2\n",
    "        \n",
    "    good_fishs_n = len(good_Fishs1) + len(good_Fishs2)\n",
    "    good_fishs_x = good_Fishs1 + good_Fishs2\n",
    "     \n",
    "    selected_fish_data2 = pd.concat([Data1.loc[Data1['fishName'].isin(good_Fishs1)], Data2.loc[Data2['fishName'].isin(good_Fishs2)]], ignore_index=True)\n",
    "\n",
    "    threshold_sizes = []\n",
    "    for fish in good_fishs_x:\n",
    "        selected_fish_data = selected_fish_data2.loc[(selected_fish_data2['fishName'] == fish)]\n",
    "        \n",
    "        ave_angles_patterns, ste_angles_patterns = [], []\n",
    "        showx = scales #angless\n",
    "\n",
    "        for pattern in range(6):\n",
    "\n",
    "            stimulus_pattern_n = pattern\n",
    "            r_stim_data = selected_fish_data.loc[(selected_fish_data['stimulus_index'] == 2 * pattern+1)]\n",
    "\n",
    "            stimulus_pattern_n = pattern + len(patterns)\n",
    "            l_stim_data = selected_fish_data.loc[(selected_fish_data['stimulus_index'] == 2 * pattern)] \n",
    "\n",
    "            df = r_stim_data.copy()\n",
    "            df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "\n",
    "            merge_data = [l_stim_data, df]\n",
    "            big_data = pd.concat(merge_data)\n",
    "            big_data_center = big_data.loc[(big_data['center_distance'] < 30)]\n",
    "\n",
    "            big_data_after5 = big_data_center.loc[(big_data_center['start_time_index'] > 6) & (big_data_center['start_time_index'] < 24)]\n",
    "            ave_angles, std_angles = [], []\n",
    "\n",
    "            ave_angle = big_data_after5[\"bout_angle\"].mean()\n",
    "            ave_angles_patterns.append(ave_angle)\n",
    "\n",
    "        scale_0_fit = np.linspace(0, 30, 50)\n",
    "\n",
    "        showx_fit = [0] + showx \n",
    "        ave_angles_patterns_fit =  [0] + ave_angles_patterns\n",
    "\n",
    "        axs[0, exp_name_i].plot(showx_fit, ave_angles_patterns_fit, color=color, linestyle=\" \", marker=\"o\", alpha=0.8)\n",
    "\n",
    "\n",
    "        N_early_points = 2 \n",
    "\n",
    "        if exp_name_i == 1:\n",
    "            showx_fit = [0] + showx[:N_early_points]\n",
    "            ave_angles_patterns_fit =  [0] + ave_angles_patterns[:N_early_points]\n",
    "        else:\n",
    "            N_early_points = 4\n",
    "            showx_fit = [0] + showx[:N_early_points] \n",
    "            ave_angles_patterns_fit =  [0] + ave_angles_patterns[:N_early_points] \n",
    "\n",
    "        new_showx_fit = np.linspace(min(showx_fit), max(showx_fit), 10) \n",
    "        new_ave_angles_patterns_fit = interpolate_data(showx_fit, ave_angles_patterns_fit, new_showx_fit, method='linear')\n",
    "\n",
    "        ## here the fitting will show\n",
    "        p0=[5, 1/3]\n",
    "        coeff_u, var_matrix = curve_fit(calculate_total_energy_fit, new_showx_fit, new_ave_angles_patterns_fit,\n",
    "                                       p0=p0, maxfev=5000, bounds = ((1, 0),(7, 1)))\n",
    "        out_fit = calculate_total_energy_fit(scale_0_fit, *coeff_u)\n",
    "        height, Amp = coeff_u\n",
    "        print(\"height:\",height,\", Amp:\",Amp)\n",
    "\n",
    "        # For the actual data\n",
    "        # Use a smooth interpolation for the actual data\n",
    "        actual_interp = interpolate.make_interp_spline(([0] + showx), ([0] + ave_angles_patterns), k=1)\n",
    "        actual_curve = actual_interp(scale_0_fit)\n",
    "        # Calculate the difference between theoretical and actual curves\n",
    "        difference = out_fit - actual_curve\n",
    "\n",
    "        # Method 3: Find where actual curve reaches X% of its maximum value\n",
    "        def find_saturation_by_max_percent(percent=0.95):\n",
    "            max_value = np.max(actual_curve)\n",
    "            threshold = percent * max_value\n",
    "            indices = np.where(out_fit >= threshold)[0]\n",
    "            if len(indices) > 0:\n",
    "                return scale_0_fit[indices[0]]\n",
    "            else:\n",
    "                print(\"None!\")\n",
    "                return None\n",
    "\n",
    "        saturation_max = find_saturation_by_max_percent(percent=0.95)\n",
    "        threshold_sizes.append(saturation_max)\n",
    "\n",
    "        axs[0, exp_name_i].plot(scale_0_fit, out_fit, color=colors[exp_name_i], alpha=0.2)#label='Theoretical motion energy curve')\n",
    "        axs[0, exp_name_i].plot(scale_0_fit, actual_curve, color=\"black\", alpha=0.2)#label='Theoretical motion energy curve')\n",
    "        axs[0, exp_name_i].axvline(x=saturation_max, color=colors[exp_name_i], linestyle='--', alpha=0.2)\n",
    "        axs[0, exp_name_i].set_ylim(-5, 60)\n",
    "    threshold_means.append(np.average(threshold_sizes))\n",
    "    threshold_stds.append(np.std(threshold_sizes))\n",
    "    threshold_Data.append(threshold_sizes)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('%s/total_motion_energy_fitting_threshold_each_fish_30_2.svg' % savefolder)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b884435",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789da828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Example data - replace with your actual data\n",
    "# Group 1: 10 datapoints\n",
    "group1 = threshold_Data[0]\n",
    "\n",
    "# Group 2: 13 datapoints\n",
    "group2 = threshold_Data[1]\n",
    "\n",
    "# Calculate averages for the bar heights\n",
    "avg_group1 = np.mean(group1)\n",
    "avg_group2 = np.mean(group2)\n",
    "std_group1 = np.std(group1)\n",
    "std_group2 = np.std(group2)\n",
    "print(\"avg:\",avg_group1, \"std:\",std_group1)\n",
    "print(\"avg:\",avg_group2, \"std:\",std_group2)\n",
    "\n",
    "# Prepare data for seaborn in a pandas DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Group 1']*len(group1) + ['Group 2']*len(group2),\n",
    "    'Value': group1 + group2\n",
    "})\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(1.8, 2))\n",
    "\n",
    "# Create the bar plot first (so it's in the background)\n",
    "bar_positions = [0, 1]  # Positions for the two groups\n",
    "bar_width = 0.6\n",
    "bar_colors = ['blue', 'orange']#['#AECEF4', '#FFCCA8']  # Light blue and light orange for bars\n",
    "\n",
    "bars = ax.bar(bar_positions, [avg_group1, avg_group2], width=bar_width, \n",
    "              color=bar_colors, alpha=0.3,)# edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add a swarm plot on top\n",
    "swarm = sns.swarmplot(x='Group', y='Value', data=data, ax=ax,\n",
    "                      palette=['blue', 'orange'], size=8, alpha=0.8,)\n",
    "\n",
    "# Add statistical annotations if needed\n",
    "# For example, you could add a p-value or significance indicator\n",
    "from scipy import stats\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "significance = \"**\" if p_value < 0.01 else (\"*\" if p_value < 0.05 else \"ns\")\n",
    "print(p_value)\n",
    "\n",
    "# Adjust layout and set a clean style\n",
    "plt.tight_layout()\n",
    "sns.despine(left=False, bottom=False)  # Remove the top and right spines\n",
    "plt.savefig('%s/total_motion_energy_fitting_threshold_dot_30_2\".svg' % savefolder)\n",
    "plt.show()\n",
    "\n",
    "t_stat, p_welch = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# 2. Mann-Whitney U test (non-parametric)\n",
    "u_stat, p_mannwhitney = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# 3. Check normality of each group (Shapiro-Wilk test)\n",
    "_, p_normal1 = stats.shapiro(group1)\n",
    "_, p_normal2 = stats.shapiro(group2)\n",
    "are_normal = (p_normal1 > 0.05) and (p_normal2 > 0.05)\n",
    "\n",
    "# Choose the most appropriate test based on normality\n",
    "if are_normal:\n",
    "    test_name = \"Welch's t-test\"\n",
    "    p_value = p_welch\n",
    "    stat_value = t_stat\n",
    "    stat_name = \"t\"\n",
    "else:\n",
    "    test_name = \"Mann-Whitney U test\"\n",
    "    p_value = p_mannwhitney\n",
    "    stat_value = u_stat\n",
    "    stat_name = \"U\"\n",
    "\n",
    "# Add significance symbols\n",
    "significance = \"**\" if p_value < 0.01 else (\"*\" if p_value < 0.05 else \"ns\")\n",
    "\n",
    "# Create the visualization (same as before with minor adjustments)\n",
    "# ...rest of the plotting code as in my previous response...\n",
    "\n",
    "# Update the statistical annotation\n",
    "ax.text(0.5, max(max(group1), max(group2)) + 0.5, \n",
    "        f'{test_name}: {stat_name}={stat_value:.2f}, p={p_value:.4f} {significance}',\n",
    "        ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics for the methods section\n",
    "print(f\"\\nStatistical summary for methods section:\")\n",
    "print(f\"Normality tests: Group 1 p={p_normal1:.4f}, Group 2 p={p_normal2:.4f}\")\n",
    "print(f\"Selected statistical test: {test_name}\")\n",
    "print(f\"Statistical results: {stat_name}={stat_value:.3f}, p={p_value:.4f}{significance}\")\n",
    "\n",
    "\"\"\"Statistical Analysis\n",
    "\n",
    "Statistical analyses were performed using Python (version X.X) with SciPy (version X.X) and NumPy (version X.X) libraries. Data are presented as mean ± standard error of the mean (SEM). Sample sizes were n=10 for group 1 and n=12 for group 2. \n",
    "\n",
    "The normality of data distribution in each group was assessed using the Shapiro-Wilk test. [CHOOSE ONE OF THE FOLLOWING BASED ON YOUR RESULTS:]\n",
    "\n",
    "[IF DATA IS NORMAL:] As both groups showed normal distribution (Shapiro-Wilk test, p > 0.05), statistical comparisons between groups were performed using Welch's t-test, which does not assume equal variances between groups.\n",
    "\n",
    "[IF DATA IS NOT NORMAL:] As the data did not meet the assumptions of normality (Shapiro-Wilk test, p < 0.05), statistical comparisons between groups were performed using the non-parametric Mann-Whitney U test.\n",
    "\n",
    "Differences were considered statistically significant at p < 0.05 (*), p < 0.01 (**), and p < 0.001 (***). All statistical plots were generated using Matplotlib (version X.X) and Seaborn (version X.X).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6477d",
   "metadata": {},
   "source": [
    "## Figure 2 k-n Response to inconsistent stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea99cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b15ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inside_outside\n",
    "## only the fish who swam in the middle of the dish in response to open-loop converging stimuli were screened\n",
    "# good_fishs_m_sand_good = ['2024_11_03_fish000', '2024_11_03_fish002', '2024_11_03_fish004', '2024_11_03_fish005', '2024_11_04_fish000', '2024_11_04_fish001', '2024_11_04_fish002', '2024_11_04_fish003', '2024_11_04_fish005', '2024_11_04_fish009', '2024_11_04_fish010', '2024_11_04_fish011', '2024_11_04_fish012', '2024_11_04_fish013', '2024_11_04_fish014', '2024_11_04_fish015', '2024_11_04_fish016', '2024_11_04_fish017', '2024_11_04_fish018', '2024_11_04_fish019', '2024_11_04_fish020', '2024_11_04_fish021', '2024_11_05_fish001', '2024_11_05_fish002', '2024_11_05_fish003', '2024_11_05_fish004', '2024_11_05_fish005', '2024_11_05_fish007', '2024_11_05_fish009', '2024_11_05_fish011', '2024_11_05_fish012', '2024_11_05_fish013']\n",
    "good_fishs_m_sand_good =[\"2024_11_03_fish000\",\n",
    "\"2024_11_03_fish002\",\n",
    "\"2024_11_03_fish004\",\n",
    "\"2024_11_04_fish005\",\n",
    "\"2024_11_04_fish010\",\n",
    "\"2024_11_04_fish012\",\n",
    "\"2024_11_04_fish016\",\n",
    "\"2024_11_04_fish020\",\n",
    "\"2024_11_05_fish001\",\n",
    "\"2024_11_05_fish004\",\n",
    "\"2024_11_05_fish013\",\n",
    "]\n",
    "good_fishs_z_sand_good = [\"2024_11_03_fish011\",\n",
    "\"2024_11_03_fish014\",\n",
    "\"2024_11_03_fish020\",\n",
    "\"2024_11_03_fish022\",\n",
    "\"2024_11_03_fish025\",\n",
    "\"2024_11_03_fish028\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1986fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "\n",
    "## inside_outside\n",
    "exp_names = [\"inside_outside_exp_medaka_sandblast_good_rig\",\"inside_outside_exp_zebra_sandblast_good_rig\"]\n",
    "\n",
    "\n",
    "## different size of disk\n",
    "angless = [[19, 27, 36, 48, 57, 65, 80.5,], [19, 27, 36, 48, 57, 65, 80.5,]]\n",
    "\n",
    "colors = [\"orange\" ,\"blue\"]\n",
    "\n",
    "good_fishss = [good_fishs_m_sand_good, good_fishs_z_sand_good]\n",
    "\n",
    "datafolder = \"/Users/yasukoisoe/PycharmProjects/fishfishfish/undulation/data_240908_spatial\"\n",
    "savefolder = \"/Users/yasukoisoe/Dropbox/Yasuko/Project_Harvard/papers/paper_working_memory/data/\"\n",
    "stimulus_pattern = []\n",
    "patterns = [0, 2,4,6,8, 10, 12]\n",
    "\n",
    "trial_num = 20\n",
    "time_start = 5\n",
    "time_stop = 25\n",
    "start_timing = 0\n",
    "middle_timing = time_start\n",
    "stop_timing = time_stop\n",
    "dt = 1./ 90\n",
    "binning1 = np.arange(start_timing, stop_timing-0.1, 0.05)\n",
    "analysis_bin = np.arange(start_timing, stop_timing-0.1, 0.2)\n",
    "\n",
    "plt.figure(figsize=(3, 2))\n",
    "\n",
    "for exp_name_i, exp_name in enumerate(exp_names):\n",
    "\n",
    "    data = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, exp_name))\n",
    "    good_fishs = good_fishss[exp_name_i]\n",
    "    selected_fish_data = data.loc[data['fishName'].isin(good_fishs)]\n",
    "\n",
    "    ave_angles_patterns, ste_angles_patterns = [], []\n",
    "    showx = angless[exp_name_i]\n",
    "\n",
    "    for pattern in range(7):\n",
    "\n",
    "        stimulus_pattern_n = pattern\n",
    "        r_stim_data = selected_fish_data.loc[(selected_fish_data['stimulus_index'] == 2 * pattern)]\n",
    "\n",
    "        stimulus_pattern_n = pattern + len(patterns)\n",
    "        l_stim_data = selected_fish_data.loc[(selected_fish_data['stimulus_index'] == 2 * pattern + 1)] ## zebrafish\n",
    "    #     l_stim_data = selected_fish_data.loc[(selected_fish_data['stimulus_index'] == pattern + 12)] ## medaka\n",
    "\n",
    "        df = r_stim_data.copy()\n",
    "        df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "\n",
    "        merge_data = [l_stim_data, df]\n",
    "        big_data = pd.concat(merge_data)\n",
    "        big_data_center = big_data.loc[(big_data['center_distance'] < 34)]\n",
    "\n",
    "        big_data_after5 = big_data_center.loc[(big_data_center['start_time_index'] > 6) & (big_data_center['start_time_index'] < 15)]\n",
    "        ave_angles = []\n",
    "        std_angles = []\n",
    "        for i in good_fishs:\n",
    "            fish_data = big_data_after5.loc[big_data_after5[\"fishName\"] == i]\n",
    "            ave_angles.append(fish_data[\"bout_angle\"].mean())\n",
    "\n",
    "        ave_angles_patterns.append(np.nanmean(ave_angles))\n",
    "        ste_angles_patterns.append(np.nanstd(ave_angles)/np.sqrt(len(good_fishs)))\n",
    "        \n",
    "\n",
    "    showx_show = [0] + showx\n",
    "    ave_angles_patterns_show = [-ave_angles_patterns[-1]] + ave_angles_patterns\n",
    "    ste_angles_patterns_show = [ste_angles_patterns[-1]] + ste_angles_patterns\n",
    "    \n",
    "    plt.fill_between(showx_show, np.array(ave_angles_patterns_show) - np.array(ste_angles_patterns_show), np.array(ave_angles_patterns_show) + np.array(ste_angles_patterns_show), \n",
    "                     color=colors[exp_name_i], alpha=0.3)\n",
    "    plt.plot(showx_show, ave_angles_patterns_show, color=colors[exp_name_i], linestyle=\"--\", marker=\"o\")\n",
    "#         plt.xlim(0, 5)\n",
    "    plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "    plt.xlim(18, 50)\n",
    "    plt.ylim(-50,50)\n",
    "\n",
    "    plt.savefig(\"%s/sandblasted/inside_outside_exp_sandblast_good_rig2.svg\" % (savefolder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cancel size effect\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "df_stats = pd.DataFrame(columns=['fish_id', 'species', 'cancel_size',])\n",
    "species = [\"medaka\", \"zebrafish\"]\n",
    "\n",
    "for exp_name_i, exp_name in enumerate(exp_names):\n",
    "\n",
    "    data = pd.read_pickle(r\"%s/df_%s.pkl\" % (datafolder, exp_name))\n",
    "    good_fishs = good_fishss[exp_name_i]\n",
    "    \n",
    "    cancel_sizes = []\n",
    "    showx = angless[exp_name_i]\n",
    "    for fish in good_fishs:\n",
    "        \n",
    "        each_selected_fish_data = data.loc[data['fishName']==fish]\n",
    "        ave_each_fish = []\n",
    "        \n",
    "        for pattern in range(7):\n",
    "\n",
    "    #         stimulus_pattern_n = pattern\n",
    "            r_stim_data = each_selected_fish_data.loc[(each_selected_fish_data['stimulus_index'] == 2 * pattern)]\n",
    "\n",
    "            stimulus_pattern_n = pattern + len(patterns)\n",
    "            l_stim_data = each_selected_fish_data.loc[(each_selected_fish_data['stimulus_index'] == 2 * pattern + 1)] \n",
    "\n",
    "            df = r_stim_data.copy()\n",
    "            df['bout_angle'] = r_stim_data['bout_angle'] * (-1)\n",
    "\n",
    "            merge_data = [l_stim_data, df]\n",
    "            big_data = pd.concat(merge_data)\n",
    "            big_data_center = big_data.loc[(big_data['center_distance'] < 34)]\n",
    "\n",
    "            big_data_after5 = big_data_center.loc[(big_data_center['start_time_index'] > 6) & (big_data_center['start_time_index'] < 15)]\n",
    "            ave_each_fish.append(big_data_after5[\"bout_angle\"].mean())\n",
    "            \n",
    "        interpolation_function = interp1d(showx, ave_each_fish, kind='linear')\n",
    "        # Generate a fine time grid for better zero-crossing detection\n",
    "        fine_time_grid = np.linspace(showx[0], showx[-1], 1000)\n",
    "        fine_data_points = interpolation_function(fine_time_grid)\n",
    "\n",
    "        # Find where the interpolated data crosses zero\n",
    "        zero_crossings = np.where(np.diff(np.sign(fine_data_points)))[0]\n",
    "        zero_times = fine_time_grid[zero_crossings]\n",
    "        cancel_sizes.append(float(zero_times))\n",
    "        \n",
    "        df2 = pd.DataFrame(\n",
    "            {'fish_id':fish, 'species':species[exp_name_i], 'cancel_size':float(zero_times)},\n",
    "            index=[0])\n",
    "        df_stats = pd.concat([df_stats, pd.DataFrame(df2)], ignore_index=True)\n",
    "        \n",
    "    print(exp_name_i, \"fish\", cancel_sizes)\n",
    "            \n",
    "        \n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c248ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a bar plot\n",
    "showx_zs = [1,1.2]\n",
    "fig, axs = plt.subplots(1, figsize=(1.2,1.5))\n",
    "medaka_cancels = [42.82432432432432, 41.83933933933934, 29.71171171171171, 33.4054054054054, 35.62162162162162, 39.192192192192195, 39.5, 26.756756756756758, 42.14714714714715, 44.97897897897898, 26.51051051051051]\n",
    "zebra_cancels = [24.97147147147147, 22.816816816816818, 27.064564564564563, 29.65015015015015, 31.12762762762763, 26.2027027027027]\n",
    "\n",
    "cancelsize_ave = [np.average(zebra_cancels), np.average(medaka_cancels)]\n",
    "cancelsize_ste = [np.std(zebra_cancels)/np.sqrt(len(zebra_cancels)), np.std(medaka_cancels)/np.sqrt(len(medaka_cancels))]\n",
    "colors = [\"blue\", \"orange\"]\n",
    "plt.bar(showx_zs, cancelsize_ave, color=colors, width=0.15)\n",
    "plt.errorbar(showx_zs, cancelsize_ave, yerr=cancelsize_ste, color=\"black\", fmt=\" \")\n",
    "\n",
    "plt.tight_layout()\n",
    "savefolder = \"/Users/yasukoisoe/Dropbox/Yasuko/Project_Harvard/papers/paper_working_memory/data\"\n",
    "plt.savefig(\"%s/sandblasted/inside_outside_exp_sandblast_good_rig_cancelsize.svg\" % (savefolder),\n",
    "                        transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
